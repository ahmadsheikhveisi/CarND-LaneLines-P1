{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Finding Lane Lines on the Road** \n",
    "\n",
    "## Writeup Report\n",
    "\n",
    "\n",
    "**Project Overview**\n",
    "\n",
    "The goal of this project is to make pipeline, using computer vision techniques implemented by OpenCV, which gets an image as the input and finds the lane lines on the road. At the end of project, this pipeline is utilized to draw the lane lines on the video recording of real-world driving situation.\n",
    "\n",
    "\n",
    "[//]: # (Image References)\n",
    "\n",
    "[image1]: ./solidWhiteRight-color_filter.jpg \"Color Selection\"\n",
    "\n",
    "[image2]: ./solidWhiteRight-gray.jpg \"GraySacle\"\n",
    "\n",
    "[image3]: ./solidWhiteRight-blur_gray.jpg \"Gaussian Blur\"\n",
    "\n",
    "[image4]: ./solidWhiteRight-edges.jpg \"Canny Edges\"\n",
    "\n",
    "[image5]: ./solidWhiteRight-masked_edges.jpg \"Masked Canny Edges\"\n",
    "\n",
    "[image6]: ./solidWhiteRight-region_image.jpg \"Region of interest\"\n",
    "\n",
    "[image7]: ./solidWhiteRight-segmented.jpg \"Lane lines segmented\"\n",
    "\n",
    "[image8]: ./solidWhiteRight.jpg \"Output Image\"\n",
    "\n",
    "[image9]: ./pipeline.png \"Pipeline Overview\"\n",
    "\n",
    "---\n",
    "\n",
    "### Reflection\n",
    "\n",
    "### 1. Lane Line Detection Pipeline Overview \n",
    "\n",
    "My pipeline consisted of six steps illustrated in the following image. \n",
    "\n",
    "![alt text][image9]\n",
    "\n",
    "#### 1. Color Selection\n",
    "\n",
    "In this stage, since the lane lines are white and yellow in this project, the yellow and white colored pixels are filtered; this is done by defining two masks: one for white range of RGB and another for yellow range of the RGB. The final filter is obtained by performing the bitwise OR operation on these masks. Finally, by performing the bitwise AND operation between the mask and the initial image, the output image is created. \n",
    "The purpose of this stage is to increase the focus of the pipeline on the interesting areas of the image whick is the lane lines. Altough in this project the lane lines are all yellow and white, in the real-world they can be of any color. Therefore, I suppose this stage just suits this project images and videos not the real-life situations.\n",
    "\n",
    "![alt text][image1]\n",
    "\n",
    "#### 2. Gray-Scale Coversion\n",
    "\n",
    "The image is converted to gray scale in this stage, so it can be used as the input to the canny-edge detection stage.\n",
    "\n",
    "![alt text][image2]\n",
    "\n",
    "#### 3. Gaussian Blurring\n",
    "\n",
    "This is done to remove the noises on image which give us strong gradients at the canny edge detection stage. The guassian kernel size is the only parameter here, and the tuning method of this parameter is described in the next stage.\n",
    "\n",
    "![alt text][image3]\n",
    "\n",
    "#### 4. Canny Edge Detection\n",
    "\n",
    "The Canny edge detection method, basically, performs the gradient over the gray-scale image to bring out where the pixels shift color. these edges can be used to distiguish between different objects in the image. \n",
    "\n",
    "there are three parameters here: \n",
    "- the low threshold\n",
    "- high threshold\n",
    "- the gaussian kernel size from the previous stage. \n",
    "\n",
    "if a pixel after the gradient has a value below the low threshold it is not an edge, if the value is greater than the high threshold, it is an edge, and if the value is between the low and high threshold, it can be an edge if it neighbors an edge. \n",
    "\n",
    "the [GUI helper tool](https://github.com/maunesh/opencv-gui-helper-tool) is used to tune these parameter. I started with the kernel size 3, low threshold 10 , high threshold 50. first, I increased kernel size until all small edges were gone and lane lines were intact. then, i increased the low threshold until the lane lines started to disapear, then i increased the high threshold until i got lane lines clear on the output image.\n",
    "\n",
    "![alt text][image4]\n",
    "\n",
    "#### 5. Masking the Region of Interest\n",
    "\n",
    "To direct the focus to where lane lines are more likely are located, this stage masks the image with a quadrilateral. the quadrilateral's height and top and bottom edges length and position are the parameters here, and they should be expressed with respect to the image size. these are chosen to get the most of the lane lines visible in the images. \n",
    "\n",
    "![alt text][image5]\n",
    "\n",
    "#### 6. Probabilistic Hough Transform\n",
    "\n",
    "Edges points from the Canny edge detection are fed into the Probabilistic Hough transform stage. the Hough transform converts each point in the image into a sin curve and each line in the image into a point in the Hough plane.\n",
    "\n",
    "\n",
    "$$\n",
    "(x_0,y_0) => x_0cos(\\theta)+y_0sin(\\theta)=\\rho\n",
    "$$\n",
    "$$\n",
    "xcos(\\theta_0)+ysin(\\theta_0) = \\rho_0 => (\\rho_0,\\theta_0)\n",
    "$$\n",
    "\n",
    "\n",
    "with this transform, if the adjacent points form a line, the sin curves in the hough space cross one point. if the random samples of the edge are chosen to detect the line, the transform is probabilistic. this technique reduces the time and processing power. The parameters for Hough transform are \n",
    "- $\\rho_0$: $\\rho$ unit in the hough space, low value causes the line detection to be more sensetive, and with a high value, the line would be lost, i found out 2 is good value \n",
    "- $\\theta_0$: $\\theta$ unit in the hough space, similar to the $\\rho_0$, i chose the minimum value for this parameter, which is one gradian\n",
    "- threshold: number of the votes for the line. the value of 15 was chosen. higher value will cause more accuracy but loss of data.\n",
    "- minimun line length: how long the the line should be to be consider as a line. i chose 10. \n",
    "- maximum gap in the line: maximum gap in a line. i chose 20. a higher value allows the algorithm to fill the gaps and results in longer lines but less accuracy since it is possible that the algorithm finds a line where there is none.\n",
    "\n",
    "![alt text][image7]\n",
    "\n",
    "**Modifying the draw_line function**\n",
    "\n",
    "In order to draw a single line on the left and right lanes, I modified the draw_lines() function by first, determining each line belongs to which side. this is done by calculating the slope of each line and comparing its endpoints to the middle line. for example, lines with the negative slope (wrt to the origin at the top left) can belong to left lane if the x of both endpoints are less than the x of the middle.\n",
    "\n",
    "also, to add more constraints, i consider a minimum slope for the lines, meaning if the line segments are too horizental they are not part of the lane lines. this is a fare assumption since lane lines are almost vertical. some line segments are rejected at this stage, meaning they have the wrong slope or they are on the wrong side of the image.\n",
    "\n",
    "after this stage, since all the endpoints of the lines which fit the condition of the lane lines are determined, a great line can be fit to all the lines since all of them have to be on one giant line. I used linear least-square regression method implemented by scipy. this function gets all the endpoints as the input and returns the slope(m), intercept (b), and the error of the regression. \n",
    "\n",
    "using the estimated m and b now we can draw the detected lane lines on the image. the endpoints of lane lines are needed to draw them on the image. since the y of the bottom and top of the region of interest are known, we can calculate the x like this:\n",
    "\n",
    "$$\n",
    "x_{top/bottom} = (y_{top/bottom} - b_{est})/m_{est}\n",
    "$$\n",
    "\n",
    "![alt text][image8]\n",
    "\n",
    "\n",
    "\n",
    "### 2. Identify potential shortcomings with your current pipeline\n",
    "\n",
    "\n",
    "One potential shortcoming would be what would happen when there are stains with the same color and orientation of the lane lines on the road. in this case, those stains are also taken into account in the linear least-square regression, making the lane line incorrectly drawn on the screen.\n",
    "\n",
    "Another shortcoming could be the region of interest, color filters, canny and hough parameters are hard coded in the pipeline. this is the problem when this pipeline is applied on a different set of images and videos.\n",
    "\n",
    "Moreover, the drawn lines on the videos are a bit flickery and unsteady perhaps due to the average methos used which calculates the lane lines based on all line segments.\n",
    "\n",
    "\n",
    "### 3. Suggest possible improvements to your pipeline\n",
    "\n",
    "A possible improvement would be to add memory to the function which processes the video frames. this would help in the situations like the challenge video where the image of the road is too noisy to detect any lane lines. with this technique, i suppose we can focuse on the region where the lane lines had been detected before and ignore the noise and other changes on the road.\n",
    "\n",
    "Another potential improvement could be to eliminate the line segements which are too far away from the others. this eliminates the noise in the lane line detection (which causes the lane lines to be unsteady) due to the small paint stains on the road which have the same oriantation and color as the lane lines.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
